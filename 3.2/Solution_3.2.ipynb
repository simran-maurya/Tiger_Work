{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b732202f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import warnings\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mlflow\n",
    "import mlflow.sklearn\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from six.moves import urllib\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from six.moves import urllib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c695acea",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''remote_server_uri = \"http://127.0.0.1:5000/\" # set to your server URI\n",
    "mlflow.set_tracking_uri(remote_server_uri)  # or set the MLFLOW_TRACKING_URI in the env\n",
    "mlflow.tracking.get_tracking_uri()'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6b019d60",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022/06/10 23:38:21 INFO mlflow.tracking.fluent: Experiment with name 'Housing_Price_Prediction_Experiment' does not exist. Creating a new experiment.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='file:///C:/Users/simran.maurya/Desktop/Tiger_Assignments/MODULE%203/3.2/mlruns/1', experiment_id='1', lifecycle_stage='active', name='Housing_Price_Prediction_Experiment', tags={}>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_name = \"Housing_Price_Prediction_Experiment\"\n",
    "mlflow.set_experiment(exp_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4cd2c51c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Random Forest Model --\n",
      "\n",
      "  RMSE: 47939.41178306655\n",
      "  MAE: 32010.50415859173\n",
      "  R2: 0.8236456210565748\n",
      "Save to: file:///C:/Users/simran.maurya/Desktop/Tiger_Assignments/MODULE%203/3.2/mlruns/1/9ed6e3056d7f44d5a7c968fe88b2b000/artifacts\n",
      "\n",
      "-- Linear Regression Model --\n",
      "\n",
      "  RMSE: 68628.19819848922\n",
      "  MAE: 49439.89599001897\n",
      "  R2: 0.6481624842804428\n",
      "Save to: file:///C:/Users/simran.maurya/Desktop/Tiger_Assignments/MODULE%203/3.2/mlruns/1/eee0855d83c449228cdc5e415dc81d30/artifacts\n"
     ]
    }
   ],
   "source": [
    "with mlflow.start_run(run_name='PARENT_RUN') as parent_run:\n",
    "    mlflow.log_param(\"parent\", \"yes\")\n",
    "    with mlflow.start_run(run_name='MATRIX_EVALUATION', nested=True) as child_run:\n",
    "        mlflow.log_param(\"child\", \"yes\")\n",
    "        def eval_metrics(actual, pred):\n",
    "            # compute relevant metrics\n",
    "            rmse = np.sqrt(mean_squared_error(actual, pred))\n",
    "            mae = mean_absolute_error(actual, pred)\n",
    "            r2 = r2_score(actual, pred)\n",
    "            return rmse, mae, r2\n",
    "        \n",
    "    \n",
    "    with mlflow.start_run(run_name='LOADING_DATA', nested=True) as child_run:\n",
    "        mlflow.log_param(\"child\", \"yes\")\n",
    "        def load_data():\n",
    "    \n",
    "            DOWNLOAD_ROOT = \"https://raw.githubusercontent.com/ageron/handson-ml2/master/\"\n",
    "            HOUSING_PATH = os.path.join(\"datasets\", \"housing\")\n",
    "            HOUSING_URL = DOWNLOAD_ROOT + \"datasets/housing/housing.tgz\"\n",
    "\n",
    "            def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):\n",
    "                if not os.path.isdir(housing_path):\n",
    "                    os.makedirs(housing_path)\n",
    "                tgz_path = os.path.join(housing_path, \"housing.tgz\")\n",
    "                urllib.request.urlretrieve(housing_url, tgz_path)\n",
    "                housing_tgz = tarfile.open(tgz_path)\n",
    "                housing_tgz.extractall(path=housing_path)\n",
    "                housing_tgz.close()\n",
    "\n",
    "            def load_housing_data(housing_path=HOUSING_PATH):\n",
    "                csv_path = os.path.join(housing_path, \"housing.csv\")\n",
    "                return pd.read_csv(csv_path)\n",
    "            fetch_housing_data()\n",
    "            housing = load_housing_data()\n",
    "            return housing\n",
    "        \n",
    "    with mlflow.start_run(run_name='SAMPLING_DATA', nested=True) as child_run:\n",
    "        mlflow.log_param(\"child\", \"yes\")\n",
    "        #categorizing median income to perform stratified sampling.\n",
    "        housing = load_data()\n",
    "        housing[\"income_cat\"] = pd.cut(housing[\"median_income\"],\n",
    "                                   bins=[0., 1.5, 3.0, 4.5, 6.,np.inf],\n",
    "                                   labels=[1, 2, 3, 4, 5])\n",
    "\n",
    "        #Performing stratified sampling.\n",
    "\n",
    "        split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "        for train_index, test_index in split.split(housing, housing[\"income_cat\"]):\n",
    "            strat_train_set = housing.loc[train_index]\n",
    "            strat_test_set = housing.loc[test_index]\n",
    "        for set_ in (strat_train_set, strat_test_set):\n",
    "            set_.drop(\"income_cat\", axis=1, inplace=True)\n",
    "\n",
    "        housing = strat_train_set.drop(\"median_house_value\", axis=1)\n",
    "        housing_labels = strat_train_set[\"median_house_value\"].copy()\n",
    "\n",
    "    with mlflow.start_run(run_name='CLEANING_DATA', nested=True) as child_run:\n",
    "        mlflow.log_param(\"child\", \"yes\")\n",
    "\n",
    "        # Data cleaning\n",
    "\n",
    "        imputer = SimpleImputer(strategy=\"median\")\n",
    "        housing_num = housing.drop(\"ocean_proximity\", axis=1) # Dropped Ocean_Proximity as it is a non-numeric column.\n",
    "        imputer.fit(housing_num)\n",
    "        X = imputer.transform(housing_num)\n",
    "        housing_tr = pd.DataFrame(X, columns=housing_num.columns)\n",
    "        housing_cat = housing[[\"ocean_proximity\"]]\n",
    "        from sklearn.preprocessing import OneHotEncoder\n",
    "        cat_encoder = OneHotEncoder()\n",
    "        housing_cat_1hot = cat_encoder.fit_transform(housing_cat) # Creating Dummy clomns for non-numeric data\n",
    "\n",
    "    with mlflow.start_run(run_name='CUSTOM_TRANSFORMER', nested=True) as child_run:\n",
    "        mlflow.log_param(\"child\", \"yes\")\n",
    "        from sklearn.base import BaseEstimator, TransformerMixin\n",
    "        rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6\n",
    "        class CombinedAttributesAdder(BaseEstimator, TransformerMixin):\n",
    "            def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs\n",
    "                self.add_bedrooms_per_room = add_bedrooms_per_room\n",
    "            def fit(self, X, y=None):\n",
    "                return self # nothing else to do\n",
    "            def transform(self, X, y=None):\n",
    "                rooms_per_household = X[:, rooms_ix] / X[:, households_ix]\n",
    "                population_per_household = X[:, population_ix] / X[:, households_ix]\n",
    "                if self.add_bedrooms_per_room:\n",
    "                    bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]\n",
    "                    return np.c_[X, rooms_per_household, population_per_household,\n",
    "                    bedrooms_per_room]\n",
    "                else:\n",
    "                    return np.c_[X, rooms_per_household, population_per_household]\n",
    "\n",
    "        attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)\n",
    "        housing_extra_attribs = attr_adder.transform(housing.values)\n",
    "\n",
    "    with mlflow.start_run(run_name='PIPELINE', nested=True) as child_run:\n",
    "        mlflow.log_param(\"child\", \"yes\")\n",
    "\n",
    "        #Transformation Pipelines\n",
    "\n",
    "        from sklearn.pipeline import Pipeline\n",
    "        from sklearn.preprocessing import StandardScaler\n",
    "        num_pipeline = Pipeline([\n",
    "         ('imputer', SimpleImputer(strategy=\"median\")), ## Imputing missing values\n",
    "         ('attribs_adder', CombinedAttributesAdder()),  ## combining attributes to make them logical\n",
    "         ('std_scaler', StandardScaler()),              ## Standardising features\n",
    "         ])\n",
    "        housing_num_tr = num_pipeline.fit_transform(housing_num)\n",
    "\n",
    "        #Full pipeline for both categorical and numerical data columns \n",
    "\n",
    "        from sklearn.compose import ColumnTransformer\n",
    "        num_attribs = list(housing_num)\n",
    "        cat_attribs = [\"ocean_proximity\"]\n",
    "        full_pipeline = ColumnTransformer([\n",
    "         (\"num\", num_pipeline, num_attribs),\n",
    "         (\"cat\", OneHotEncoder(), cat_attribs),\n",
    "         ])\n",
    "        housing_prepared = full_pipeline.fit_transform(housing)\n",
    "    with mlflow.start_run(run_name='TRAINING_MODEL', nested=True) as child_run:\n",
    "        mlflow.log_param(\"child\", \"yes\")\n",
    "        # train a model with given parameters\n",
    "\n",
    "        warnings.filterwarnings(\"ignore\")\n",
    "        np.random.seed(40) \n",
    "\n",
    "        # Making a Random Forest Model\n",
    "\n",
    "\n",
    "        with mlflow.start_run(run_name='RANDOM_FOREST_MODEL', nested=True) as child_run:\n",
    "            mlflow.log_param(\"child\", \"yes\")\n",
    "            from sklearn.ensemble import RandomForestRegressor\n",
    "            forest_reg = RandomForestRegressor()\n",
    "            forest_reg.fit(housing_prepared, housing_labels)\n",
    "            housing_predictions = forest_reg.predict(housing_prepared)\n",
    "\n",
    "            #Performing Grid Search\n",
    "\n",
    "            from sklearn.model_selection import GridSearchCV\n",
    "            param_grid = [\n",
    "                {'n_estimators': [3, 10, 30], 'max_features': [2, 4, 6, 8]},\n",
    "                {'bootstrap': [False], 'n_estimators': [3, 10], 'max_features': [2, 3, 4]},\n",
    "             ]\n",
    "            forest_reg = RandomForestRegressor()\n",
    "            grid_search = GridSearchCV(forest_reg, param_grid, cv=5,\n",
    "                                       scoring='neg_mean_squared_error',\n",
    "            return_train_score=True)\n",
    "            grid_search.fit(housing_prepared, housing_labels)\n",
    "            cvres = grid_search.cv_results_\n",
    "            feature_importances = grid_search.best_estimator_.feature_importances_\n",
    "            feature_importances\n",
    "\n",
    "            extra_attribs = [\"rooms_per_hhold\", \"pop_per_hhold\", \"bedrooms_per_room\"]\n",
    "            cat_encoder = full_pipeline.named_transformers_[\"cat\"]\n",
    "            cat_one_hot_attribs = list(cat_encoder.categories_[0])\n",
    "            attributes = num_attribs + extra_attribs + cat_one_hot_attribs\n",
    "            sorted(zip(feature_importances, attributes), reverse=True)\n",
    "\n",
    "            final_model = grid_search.best_estimator_\n",
    "            X_test = strat_test_set.drop(\"median_house_value\", axis=1)\n",
    "            y_test = strat_test_set[\"median_house_value\"].copy()\n",
    "            X_test_prepared = full_pipeline.transform(X_test)\n",
    "            final_predictions = final_model.predict(X_test_prepared)\n",
    "\n",
    "            # Evaluate Metrics\n",
    "\n",
    "            (rmse, mae, r2) = eval_metrics(y_test, final_predictions)\n",
    "\n",
    "            print(\"\\n-- Random Forest Model --\\n\")\n",
    "            print(\"  RMSE: %s\" % rmse)\n",
    "            print(\"  MAE: %s\" % mae)\n",
    "            print(\"  R2: %s\" % r2)\n",
    "\n",
    "            # metrics, and model to MLflow\n",
    "            mlflow.log_param(\"Model\", \"Random Forest Model\")\n",
    "            mlflow.log_metric(key=\"rmse\", value=rmse)\n",
    "            mlflow.log_metrics({\"mae\": mae, \"r2\": r2})\n",
    "            print(\"Save to: {}\".format(mlflow.get_artifact_uri()))\n",
    "\n",
    "            mlflow.sklearn.log_model(forest_reg, \"model\")\n",
    "\n",
    "        with mlflow.start_run(run_name='LINEAR_REGRESSION_MODEL', nested=True) as child_run:\n",
    "            mlflow.log_param(\"child\", \"yes\")\n",
    "            from sklearn.linear_model import LinearRegression\n",
    "            lin_reg = LinearRegression()\n",
    "            lin_reg.fit(housing_prepared, housing_labels)\n",
    "            from sklearn.metrics import mean_squared_error\n",
    "            housing_predictions = lin_reg.predict(housing_prepared)\n",
    "\n",
    "            # Evaluate Metrics\n",
    "\n",
    "            (rmse, mae, r2) = eval_metrics(housing_labels, housing_predictions)\n",
    "\n",
    "            print(\"\\n-- Linear Regression Model --\\n\")\n",
    "            print(\"  RMSE: %s\" % rmse)\n",
    "            print(\"  MAE: %s\" % mae)\n",
    "            print(\"  R2: %s\" % r2)\n",
    "\n",
    "            # metrics, and model to MLflow\n",
    "            mlflow.log_param(\"Model\", \"Linear Regression Model\")\n",
    "            mlflow.log_metric(key=\"rmse\", value=rmse)\n",
    "            mlflow.log_metrics({\"mae\": mae, \"r2\": r2})\n",
    "            print(\"Save to: {}\".format(mlflow.get_artifact_uri()))\n",
    "\n",
    "            mlflow.sklearn.log_model(lin_reg, \"model\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3cd63e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86923351",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
